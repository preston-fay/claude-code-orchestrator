"""
AI Contribution Analyzer

Analyzes git commit history to attribute contributions to human vs AI contributors.
Detects patterns like Co-Authored-By, [claude], [ai] markers, and AI code generation signatures.

Outputs:
- Commit attribution (human/ai/collaborative)
- Line changes by contributor type
- Files modified by contributor type
- Temporal trends in AI vs human contributions
"""

import json
import re
import subprocess
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import logging

logger = logging.getLogger(__name__)


@dataclass
class CommitAttribution:
    """Attribution data for a single commit"""

    sha: str
    author: str
    date: str
    message: str
    contributor_type: str  # human, ai, collaborative
    lines_added: int
    lines_deleted: int
    files_changed: int
    ai_indicators: List[str] = field(default_factory=list)


@dataclass
class ContributionMetrics:
    """Overall contribution attribution metrics"""

    metric: str = "contribution_attribution"
    period: str = ""
    collection_timestamp: str = ""
    commits: List[Dict] = field(default_factory=list)
    summary: Dict = field(default_factory=dict)


class AIContributionAnalyzer:
    """Analyze git history to attribute contributions to human vs AI"""

    # AI contribution indicators
    AI_PATTERNS = [
        r"Co-Authored-By:.*Claude",
        r"\[claude\]",
        r"\[ai\]",
        r"\[ai-generated\]",
        r"Generated with.*Claude",
        r"Co-Authored-By:.*noreply@anthropic\.com",
        r"Assisted-by:.*Claude",
    ]

    # AI code generation signatures in diffs
    CODE_GENERATION_SIGNATURES = [
        r"# Generated by Claude",
        r"// Generated by Claude",
        r"/\* Generated by Claude \*/",
        r"Generated with \[Claude Code\]",
    ]

    def __init__(
        self,
        repo_path: Optional[Path] = None,
        days_back: int = 90,
        project_root: Optional[Path] = None,
    ):
        """
        Initialize AI contribution analyzer.

        Args:
            repo_path: Path to git repository (default: current directory)
            days_back: Number of days of history to analyze (default: 90)
            project_root: Root directory for output (default: current directory)
        """
        self.repo_path = Path(repo_path) if repo_path else Path.cwd()
        self.days_back = days_back

        # Setup output directory
        if project_root:
            self.output_dir = Path(project_root) / ".claude" / "metrics" / "contributions"
        else:
            self.output_dir = Path.cwd() / ".claude" / "metrics" / "contributions"
        self.output_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"Initialized AI contribution analyzer for {self.repo_path}")

    def _run_git_command(self, args: List[str]) -> str:
        """
        Run a git command and return output.

        Args:
            args: Git command arguments

        Returns:
            Command output as string
        """
        try:
            result = subprocess.run(
                ["git", "-C", str(self.repo_path)] + args,
                capture_output=True,
                text=True,
                check=True,
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError as e:
            logger.error(f"Git command failed: {e}")
            logger.error(f"stderr: {e.stderr}")
            raise

    def _detect_ai_indicators(
        self, commit_message: str, commit_body: str
    ) -> Tuple[bool, List[str]]:
        """
        Detect AI contribution indicators in commit message and body.

        Args:
            commit_message: Commit message (first line)
            commit_body: Full commit body

        Returns:
            Tuple of (has_ai_indicators, list_of_matched_patterns)
        """
        indicators = []
        full_text = f"{commit_message}\n{commit_body}"

        for pattern in self.AI_PATTERNS:
            if re.search(pattern, full_text, re.IGNORECASE):
                indicators.append(pattern)

        return len(indicators) > 0, indicators

    def _get_commit_diff(self, sha: str) -> str:
        """
        Get diff for a commit.

        Args:
            sha: Commit SHA

        Returns:
            Diff text
        """
        try:
            return self._run_git_command(["show", "--format=", sha])
        except Exception as e:
            logger.warning(f"Could not get diff for {sha}: {e}")
            return ""

    def _detect_ai_code_generation(self, diff: str) -> bool:
        """
        Detect AI code generation signatures in diff.

        Args:
            diff: Git diff text

        Returns:
            True if AI code generation detected
        """
        for signature in self.CODE_GENERATION_SIGNATURES:
            if re.search(signature, diff, re.IGNORECASE):
                return True
        return False

    def _classify_commit(
        self, commit_data: Dict, commit_body: str, diff: str
    ) -> Tuple[str, List[str]]:
        """
        Classify commit as human, ai, or collaborative.

        Args:
            commit_data: Commit metadata
            commit_body: Full commit body
            diff: Commit diff

        Returns:
            Tuple of (contributor_type, ai_indicators)
        """
        # Check for AI indicators in commit message/body
        has_ai_message, message_indicators = self._detect_ai_indicators(
            commit_data["message"], commit_body
        )

        # Check for AI code generation in diff
        has_ai_code = self._detect_ai_code_generation(diff)

        all_indicators = message_indicators.copy()
        if has_ai_code:
            all_indicators.append("AI code generation signature detected")

        # Classification logic
        if has_ai_message and has_ai_code:
            return "collaborative", all_indicators
        elif has_ai_message:
            return "collaborative", all_indicators
        elif has_ai_code:
            return "ai", all_indicators
        else:
            return "human", []

    def _parse_commit_stats(self, sha: str) -> Tuple[int, int, int]:
        """
        Parse commit statistics (lines added/deleted, files changed).

        Args:
            sha: Commit SHA

        Returns:
            Tuple of (lines_added, lines_deleted, files_changed)
        """
        try:
            # Get numstat for commit
            stats = self._run_git_command(["show", "--numstat", "--format=", sha])

            lines_added = 0
            lines_deleted = 0
            files_changed = 0

            for line in stats.split("\n"):
                if not line.strip():
                    continue

                parts = line.split("\t")
                if len(parts) < 3:
                    continue

                added_str, deleted_str, filename = parts[0], parts[1], parts[2]

                # Handle binary files (marked as "-")
                if added_str != "-":
                    lines_added += int(added_str)
                if deleted_str != "-":
                    lines_deleted += int(deleted_str)

                files_changed += 1

            return lines_added, lines_deleted, files_changed

        except Exception as e:
            logger.warning(f"Could not parse stats for {sha}: {e}")
            return 0, 0, 0

    def analyze_contributions(self) -> ContributionMetrics:
        """
        Analyze git history to attribute contributions.

        Returns:
            ContributionMetrics object
        """
        logger.info(f"Analyzing contributions (last {self.days_back} days)")

        # Calculate date range
        since_date = (datetime.now() - timedelta(days=self.days_back)).strftime("%Y-%m-%d")

        # Get commit log with full details
        log_format = "%H|%an|%ai|%s"
        log_output = self._run_git_command(
            ["log", f"--since={since_date}", f"--format={log_format}", "--no-merges"]
        )

        if not log_output:
            logger.warning("No commits found in date range")
            metrics = ContributionMetrics(
                period=f"{since_date}/{datetime.now().strftime('%Y-%m-%d')}",
                collection_timestamp=datetime.now().isoformat(),
                commits=[],
                summary={
                    "total_commits": 0,
                    "human_commits": 0,
                    "ai_commits": 0,
                    "collaborative_commits": 0,
                    "human_lines_added": 0,
                    "ai_lines_added": 0,
                    "collaborative_lines_added": 0,
                    "human_percentage": 0,
                    "ai_percentage": 0,
                    "collaborative_percentage": 0,
                },
            )
            return metrics

        commits = []
        total_commits = 0
        human_commits = 0
        ai_commits = 0
        collaborative_commits = 0
        human_lines_added = 0
        ai_lines_added = 0
        collaborative_lines_added = 0

        for line in log_output.split("\n"):
            if not line.strip():
                continue

            parts = line.split("|")
            if len(parts) < 4:
                continue

            sha, author, date, message = parts[0], parts[1], parts[2], parts[3]

            # Get full commit body
            commit_body = self._run_git_command(["show", "--format=%B", "-s", sha])

            # Get commit diff
            diff = self._get_commit_diff(sha)

            # Parse commit stats
            lines_added, lines_deleted, files_changed = self._parse_commit_stats(sha)

            # Classify commit
            commit_data = {"message": message}
            contributor_type, ai_indicators = self._classify_commit(commit_data, commit_body, diff)

            # Build commit attribution
            commit_attr = CommitAttribution(
                sha=sha,
                author=author,
                date=date,
                message=message,
                contributor_type=contributor_type,
                lines_added=lines_added,
                lines_deleted=lines_deleted,
                files_changed=files_changed,
                ai_indicators=ai_indicators,
            )

            commits.append(asdict(commit_attr))

            # Update counters
            total_commits += 1
            if contributor_type == "human":
                human_commits += 1
                human_lines_added += lines_added
            elif contributor_type == "ai":
                ai_commits += 1
                ai_lines_added += lines_added
            elif contributor_type == "collaborative":
                collaborative_commits += 1
                collaborative_lines_added += lines_added

            # Log progress every 50 commits
            if total_commits % 50 == 0:
                logger.info(f"Processed {total_commits} commits...")

        # Calculate percentages
        human_percentage = (human_commits / total_commits * 100) if total_commits > 0 else 0
        ai_percentage = (ai_commits / total_commits * 100) if total_commits > 0 else 0
        collaborative_percentage = (
            (collaborative_commits / total_commits * 100) if total_commits > 0 else 0
        )

        total_lines_added = human_lines_added + ai_lines_added + collaborative_lines_added
        human_lines_percentage = (
            (human_lines_added / total_lines_added * 100) if total_lines_added > 0 else 0
        )
        ai_lines_percentage = (
            (ai_lines_added / total_lines_added * 100) if total_lines_added > 0 else 0
        )
        collaborative_lines_percentage = (
            (collaborative_lines_added / total_lines_added * 100) if total_lines_added > 0 else 0
        )

        # Build period string
        end_date = datetime.now().strftime("%Y-%m-%d")
        period = f"{since_date}/{end_date}"

        metrics = ContributionMetrics(
            period=period,
            collection_timestamp=datetime.now().isoformat(),
            commits=commits,
            summary={
                "total_commits": total_commits,
                "human_commits": human_commits,
                "ai_commits": ai_commits,
                "collaborative_commits": collaborative_commits,
                "human_percentage": round(human_percentage, 2),
                "ai_percentage": round(ai_percentage, 2),
                "collaborative_percentage": round(collaborative_percentage, 2),
                "human_lines_added": human_lines_added,
                "ai_lines_added": ai_lines_added,
                "collaborative_lines_added": collaborative_lines_added,
                "total_lines_added": total_lines_added,
                "human_lines_percentage": round(human_lines_percentage, 2),
                "ai_lines_percentage": round(ai_lines_percentage, 2),
                "collaborative_lines_percentage": round(collaborative_lines_percentage, 2),
            },
        )

        # Save to JSON
        output_file = self.output_dir / "attribution.json"
        with open(output_file, "w") as f:
            json.dump(asdict(metrics), f, indent=2)

        logger.info(f"Analyzed {total_commits} commits:")
        logger.info(f"  Human: {human_commits} ({human_percentage:.1f}%)")
        logger.info(f"  AI: {ai_commits} ({ai_percentage:.1f}%)")
        logger.info(f"  Collaborative: {collaborative_commits} ({collaborative_percentage:.1f}%)")
        logger.info(
            f"  Lines - Human: {human_lines_percentage:.1f}%, AI: {ai_lines_percentage:.1f}%, Collaborative: {collaborative_lines_percentage:.1f}%"
        )

        return metrics


def main():
    """CLI entry point for AI contribution analysis"""
    import argparse

    parser = argparse.ArgumentParser(description="Analyze AI vs human contributions in git history")
    parser.add_argument("--repo", type=Path, help="Repository path (default: current directory)")
    parser.add_argument(
        "--days", type=int, default=90, help="Number of days of history to analyze (default: 90)"
    )
    parser.add_argument(
        "--output", type=Path, help="Output directory (default: .claude/metrics/contributions/)"
    )
    parser.add_argument("--verbose", action="store_true", help="Enable verbose logging")

    args = parser.parse_args()

    # Setup logging
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(
        level=log_level, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )

    # Run analysis
    try:
        analyzer = AIContributionAnalyzer(
            repo_path=args.repo,
            days_back=args.days,
            project_root=args.output.parent.parent.parent if args.output else None,
        )

        analyzer.analyze_contributions()

    except Exception as e:
        logger.error(f"Analysis failed: {e}")
        raise


if __name__ == "__main__":
    main()
