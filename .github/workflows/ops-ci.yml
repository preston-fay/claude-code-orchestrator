name: Ops CI - Performance & Monitoring

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    - cron: '0 6 * * *'  # Daily at 6 AM UTC

jobs:
  ops-verify:
    name: Ops Layer Verification
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"
          pip install structlog prometheus_client python-dotenv opentelemetry-sdk opentelemetry-instrumentation-fastapi

      - name: Verify registry integrity
        run: |
          python -c "from src.registry.manager import RegistryManager; from pathlib import Path; m = RegistryManager(Path.cwd()); r = m.verify_integrity(); print(f\"Valid: {r['valid']}\"); exit(0 if r['valid'] else 1)"

      - name: Test secrets precedence
        run: |
          # Test environment variable precedence
          export TEST_SECRET="from_env"
          python -c "from src.ops.secrets import get_secret; assert get_secret('TEST_SECRET') == 'from_env'; print('✓ Secrets working')"

      - name: Test structured logging
        run: |
          python -c "from src.ops.logging import configure_logging, get_logger, bind_context; configure_logging(json=True); logger = get_logger('test'); bind_context(test_id='123'); logger.info('test_message'); print('✓ Logging working')"

      - name: Test metrics
        run: |
          python -c "from src.ops.metrics import http_requests_total, get_metrics; http_requests_total.labels(route='/test', method='GET', status=200).inc(); m = get_metrics(); assert b'http_requests_total' in m; print('✓ Metrics working')"

  perf-api:
    name: API Performance Tests
    runs-on: ubuntu-latest
    needs: ops-verify

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"
          pip install structlog prometheus_client python-dotenv

      - name: Start API server
        run: |
          cd $GITHUB_WORKSPACE
          python -m uvicorn src.server.app:app --host 0.0.0.0 --port 8000 &
          sleep 5

      - name: Wait for server
        run: |
          for i in {1..30}; do
            if curl -f http://localhost:8000/health; then
              echo "Server is up"
              break
            fi
            echo "Waiting for server..."
            sleep 1
          done

      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Run k6 performance tests
        run: |
          k6 run perf/api/smoke_test.js --out json=perf/api/results.json
        continue-on-error: true

      - name: Check performance thresholds
        run: |
          # Parse results and check thresholds
          python -c "
          import json
          from pathlib import Path

          results_file = Path('perf/api/results.json')
          if not results_file.exists():
              print('No results file found')
              exit(0)

          # Read last line (summary)
          with open(results_file) as f:
              lines = f.readlines()
              if lines:
                  summary = json.loads(lines[-1])
                  if summary.get('type') == 'Point' and 'data' in summary:
                      print('Performance test completed')
                      exit(0)

          print('Performance test results incomplete')
          exit(0)
          "

      - name: Upload performance results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: perf-api-results
          path: perf/api/
          retention-days: 30

  cache-tests:
    name: Cache Layer Tests
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"
          pip install pyarrow

      - name: Test cache operations
        run: |
          python -c "
          from src.data.cache import get_cache
          from pathlib import Path
          import pyarrow as pa

          cache = get_cache()

          # Test cache miss
          result = cache.get('SELECT 1', {})
          assert result is None, 'Expected cache miss'

          # Test cache set
          table = pa.table({'x': [1, 2, 3]})
          cache.set('SELECT 1', table, {}, ttl_seconds=60)

          # Test cache hit
          result = cache.get('SELECT 1', {})
          assert result is not None, 'Expected cache hit'
          assert len(result) == 3, 'Expected 3 rows'

          # Test stats
          stats = cache.get_stats()
          assert stats['entries'] == 1, 'Expected 1 cache entry'

          print('✓ Cache tests passed')
          "

      - name: Test cache invalidation
        run: |
          python -c "
          from src.data.cache import get_cache
          import pyarrow as pa

          cache = get_cache()

          # Create cache entries
          table = pa.table({'x': [1]})
          cache.set('SELECT * FROM users', table)
          cache.set('SELECT * FROM orders', table)

          # Invalidate pattern
          count = cache.invalidate('*users*')
          assert count == 1, 'Expected 1 entry invalidated'

          # Check remaining
          stats = cache.get_stats()
          assert stats['entries'] == 1, 'Expected 1 entry remaining'

          print('✓ Invalidation tests passed')
          "
