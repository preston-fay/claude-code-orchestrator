# Environment Configuration
# Copy this file to .env and update with your values
# NEVER commit .env to version control

# Data directories
DATA_DIR=./data
MODEL_DIR=./models
ANALYTICS_DIR=./analytics

# Random seed for reproducibility
SEED=42

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/orchestrator.log

# Data pipeline configuration
BATCH_SIZE=1000
MAX_WORKERS=4

# Model training
TRAIN_TEST_SPLIT=0.8
VALIDATION_SPLIT=0.1
EPOCHS=10
LEARNING_RATE=0.001

# MLflow (optional - uncomment if using)
# MLFLOW_TRACKING_URI=./mlruns
# MLFLOW_EXPERIMENT_NAME=orchestrator-experiments

# DVC (optional - uncomment if using)
# DVC_REMOTE_NAME=origin
# DVC_REMOTE_URL=s3://my-bucket/dvc-storage

# Database (optional - uncomment if needed)
# DB_HOST=localhost
# DB_PORT=5432
# DB_NAME=orchestrator
# DB_USER=user
# DB_PASSWORD=changeme

# API keys
# OPENAI_API_KEY=sk-...  # Optional: For OpenAI integration

# REQUIRED for real AI agent execution (otherwise uses stub mode)
# Get your API key from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-your-api-key-here

# Cloud storage (optional - uncomment if needed)
# AWS_ACCESS_KEY_ID=AKIA...
# AWS_SECRET_ACCESS_KEY=...
# AWS_DEFAULT_REGION=us-east-1
# S3_BUCKET=my-data-bucket

# Orchestrator settings
ORCHESTRATOR_STATE_FILE=.claude/orchestrator_state.json
CHECKPOINT_STORAGE_PATH=.claude/checkpoints/
